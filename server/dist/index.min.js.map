{"version":3,"sources":["index.js"],"names":["model","express","require","multer","createCanvas","loadImage","path","app","storage","memoryStorage","upload","regeneratorRuntime","async","_context","prev","next","awrap","tf","loadGraphModel","fromTFHub","port","sent","console","log","stop","single","req","res","imageBuffer","img","canvas","tensor","segmentation","mask","maskImageData","maskCanvas","maskCtx","maskData","segmentedImageBuffer","segmentedImageBase64","_context2","file","abrupt","loadModel","status","send","error","buffer","width","height","getContext","drawImage","browser","fromPixels","expandDims","executeAsync","squeeze","mul","toInt","dataSync","putImageData","ImageData","Uint8ClampedArray","from","toBuffer","toString","json","segmentedImage","concat","t0"],"mappings":"aAAA,IAgBIA,MAhBEC,QAAUC,QAAQ,WAClBC,OAASD,QAAQ,UADjBD,GAAOC,QAAGA,kCAGoBA,QAAQ,UAApCE,sBAAAA,aAAcC,mBAAAA,UAFhBF,GAAMD,QAAGA,MAITI,KAAOJ,QAAQ,QAGfK,IAAMN,UALJG,KAAAA,IACAI,QAAUL,OAAlBM,gBASMC,OAASP,OAAO,CAAEK,QAASA,UALjC,SAAYP,YAAZ,OAAAU,mBAAAC,MAAA,SAAAC,GAAA,OAAA,OAAAA,EAAAC,KAAAD,EAAAE,MAAA,KAAA,EAAA,OAAAF,EAAAE,KAAA,EAAAJ,mBAAAK,MAGAC,GAAAC,eAAA,qDAAA,CAAAC,WAAA,KAHA,KAAA,EACMC,MADNP,EAAAQ,KAWIC,QAAQC,IAAI,gBAXhB,KAAA,EAAA,IAAA,MAAA,OAAAV,EAAAW,UAKwBhB,YAGxBD,IAAIP,KAAJ,gBAAAU,OAAAe,OAAA,SAAA,SAAAC,EAAAC,GAAA,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAA,OAAA5B,mBAAAC,MAAA,SAAA4B,GAAA,OAAA,OAAAA,EAAA1B,KAAA0B,EAAAzB,MAAA,KAAA,EAAA,GAUSW,EAAIe,KAVb,CAAAD,EAAAzB,KAAA,EAAA,MAAA,OAAAyB,EAAAE,OAAA,SACeC,EAAfC,OAAA,KAAAC,KAAA,CAAAC,MAAA,sBADA,KAAA,EAAA,OAAAN,EAAA1B,KAAA,EACAc,EAAAF,EAAAe,KAAAM,OADAP,EAAAzB,KAAA,EAAAJ,mBAAAK,MACAX,UAAAuB,IADA,KAAA,EAAA,OACAC,EADAW,EAAAnB,KAE2FF,EAAWf,aAAAyB,EAAAmB,MAAAnB,EAAAoB,QADtGnB,EAAAoB,WAAA,MAmBYC,UAAUtB,EAAK,EAAG,GAItBE,GArBJT,EAAAL,GAAYmC,QAAAC,WAAZvB,IAqBoBwB,WAAW,GAxBnCd,EAAAzB,KAAA,GAAAJ,mBAAAK,MACAhB,MAAAuD,aAAAxB,IADA,KAAA,GACAC,EADAQ,EAAAnB,KACAY,EAAAD,EAAA,GAAAwB,UAKatB,EAAAD,EAAAwB,IAAA,KAAAC,QAEbvB,EAAA/B,aAAAyB,EAAAmB,MAAAnB,EAAAoB,QA2Bcb,EAAUD,EAAWe,WAAW,MA1BrCb,EAATH,EAA0ByB,WAAwBvB,EAAAwB,aAAA,IAAAC,UAAAC,kBAAAC,KAAA1B,GAAAR,EAAAmB,MAAAnB,EAAAoB,QAAA,EAAA,GAAAX,EAAAH,EAAA6B,SAAA,cAAAzB,EAAAD,EAAA2B,SAAA,UAAAtC,EAAAuC,KAAA,CAAAC,eAAA,0BAAAC,OAAA7B,KATlDC,EAAAzB,KAAA,GAAA,MAAA,KAAA,GAAAyB,EAAA1B,KAAA,GAAA0B,EAAA6B,GAAA7B,EAAA,MAAA,GASkDlB,QAAAwB,MAAA,6BAAAN,EAAA6B,IAEZvB,EAAAA,OAAO,KAAAD,KAAA,CAAAC,MAAA,oCAX7C,KAAA,GAAA,IAAA,MAAA,OAAAN,EAAAhB,SAAA,KAAA,KAAA,CAAA,CAAA,EAAA,QAecI,IAAAA,OAAAA,KAAAA,WANoCN,QAAAC,IAAA,yCAAA6C,OAAAhD","file":"index.min.js","sourcesContent":["const express = require(\"express\");\nconst multer = require(\"multer\");\nconst tf = require(\"@tensorflow/tfjs-node\");\nconst { createCanvas, loadImage } = require(\"canvas\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\n\n// Initialize express app\nconst app = express();\nconst port = 4000;\n\n// Set up multer for file uploads\nconst storage = multer.memoryStorage();\nconst upload = multer({ storage: storage });\n\n// Load the pre-trained model (DeepLabV3 for segmentation, you can choose another model)\nlet model;\nasync function loadModel() {\n    model = await tf.loadGraphModel('https://tfhub.dev/tensorflow/deeplabv3/1/default/1', {fromTFHub: true});\n    console.log(\"Model Loaded\");\n}\n\nloadModel(); // Load the model when server starts\n\n// API to segment the image\napp.post(\"/segmentImage\", upload.single(\"image\"), async (req, res) => {\n    if (!req.file) {\n        return res.status(400).send({ error: \"No file uploaded\" });\n    }\n\n    try {\n        const imageBuffer = req.file.buffer;\n        const img = await loadImage(imageBuffer);\n        \n        const canvas = createCanvas(img.width, img.height);\n        const ctx = canvas.getContext(\"2d\");\n        ctx.drawImage(img, 0, 0);\n\n        // Convert image to Tensor\n        let tensor = tf.browser.fromPixels(canvas);\n        tensor = tensor.expandDims(0); // Add batch dimension\n\n        // Run segmentation\n        const segmentation = await model.executeAsync(tensor);\n        \n        // Here we are assuming the model returns the segmentation mask in the first element\n        const mask = segmentation[0].squeeze(); // Remove batch dimension\n        \n        // Convert mask tensor to an image\n        const maskImageData = mask.mul(255).toInt();\n        const maskCanvas = createCanvas(img.width, img.height);\n        const maskCtx = maskCanvas.getContext(\"2d\");\n        const maskData = maskImageData.dataSync();\n        \n        maskCtx.putImageData(new ImageData(Uint8ClampedArray.from(maskData), img.width, img.height), 0, 0);\n\n        // Convert segmented image to buffer\n        const segmentedImageBuffer = maskCanvas.toBuffer(\"image/jpeg\");\n\n        // Return the segmented image as base64\n        const segmentedImageBase64 = segmentedImageBuffer.toString(\"base64\");\n        res.json({ segmentedImage: `data:image/jpeg;base64,${segmentedImageBase64}` });\n    } catch (error) {\n        console.error(\"Error during segmentation:\", error);\n        res.status(500).send({ error: \"Error during image segmentation\" });\n    }\n});\n\n// Start the server\napp.listen(port, () => {\n    console.log(`Server is running on http://localhost:${port}`);\n});\n"]}